# ğŸ›¡ï¸ Social Sentinel: Analyse de Sentiment en Temps RÃ©el

- **Module:** Clusters Big Data & SystÃ¨mes DistribuÃ©s
- **AnnÃ©e:** 2025/2026
- **Auteur:** [Votre Nom]

---

## ğŸ“– Description du Projet

Ce projet implÃ©mente une architecture Big Data complÃ¨te ("Kappa Architecture") pour surveiller la e-rÃ©putation des grandes entreprises marocaines (Maroc Telecom, Orange, RAM, etc.).

Le systÃ¨me ingÃ¨re des flux de rÃ©seaux sociaux en temps rÃ©el, analyse le sentiment des messages (Positif/NÃ©gatif/Neutre) grÃ¢ce au NLP, et dÃ©clenche des alertes immÃ©diates en cas de crise (ex: chute brutale de satisfaction due Ã  une panne rÃ©seau).

### Objectifs atteints :

- **Ingestion Haute FrÃ©quence:** Supporte des pics de charge (mode "Burst")
- **Faible Latence:** DÃ©tection de crise en < 10 secondes
- **Visualisation:** Dashboard interactif Web (Streamlit)
- **Stockage:** Historisation complÃ¨te et agrÃ©gations temporelles

---

## ğŸ—ï¸ Architecture Technique

Le pipeline de donnÃ©es suit le flux suivant :

1. **GÃ©nÃ©rateur (Python):** Simule un flux de rÃ©seaux sociaux rÃ©aliste avec des scÃ©narios de crise pondÃ©rÃ©s
2. **Ingestion (Apache Kafka):** Tamponne les messages dans le topic `social_posts` (3 partitions)
3. **Traitement (Apache Spark Streaming):**
   - Consommation des micro-batchs
   - Nettoyage et Analyse de Sentiment (TextBlob)
   - AgrÃ©gation par fenÃªtres glissantes (Windowing 1 min)
4. **Stockage (Apache Cassandra):** Sauvegarde des tweets bruts et des mÃ©triques agrÃ©gÃ©es
5. **Visualisation (Streamlit + Plotly):** Interface de monitoring temps rÃ©el avec systÃ¨me d'alerte

---

## DÃ©monstration & Screenshots

### 1. Dashboard en mode "Surveillance Normale"

Cette vue montre le flux de donnÃ©es en temps rÃ©el. On observe les volumes de posts par marque et une courbe de sentiment stable.

> *courbes Ã©volutifs:*
![courbes Ã©volutifs](ressources/newplot.png)

### 2. DÃ©tection de Crise (Simulation)

Lorsqu'une marque (ex: Maroc Telecom) subit une vague de commentaires nÃ©gatifs, le systÃ¨me dÃ©clenche une alerte visuelle rouge et notifie l'opÃ©rateur en moins de 5 secondes.

> *chute de la rÃ©putation: courbe en rouge "orange maroc":*
![chute de rÃ©putation](ressources/image.png)

Dashboard en sa totalitÃ©:

![dashboard](ressources/image-1.png)

### 3. Preuve de Stockage (Cassandra)

Vue de la base de donnÃ©es montrant les tweets bruts et les scores de sentiment associÃ©s, prouvant que le pipeline d'Ã©criture fonctionne.

> ![commande cassandra pour le stockage](ressources/Screenshot%20from%202026-01-08%2014-06-20.png)*
![alt text](ressources/Screenshot%20from%202026-01-08%2014-28-31.png) 
![alt text](ressources/Screenshot%20from%202026-01-08%2014-06-33.png)

---

## Installation et DÃ©marrage

### PrÃ©requis

- Docker (pour Kafka et Cassandra)
- Python 3.10+
- Java 11 (Requis pour Spark)

### 1. DÃ©marrer l'Infrastructure

Assurez-vous que les conteneurs Docker tournent :

```bash
# DÃ©marrer Cassandra
docker run --name cassandra -p 9042:9042 -d cassandra:4.1

# VÃ©rifier Kafka (dÃ©jÃ  installÃ© sur votre machine/docker)
# CrÃ©er le topic si nÃ©cessaire :
docker exec -it kafka kafka-topics --create --topic social_posts --partitions 3 --bootstrap-server localhost:9092
```

### 2. Installer les dÃ©pendances Python

```bash
pip install -r requirements.txt
python -m textblob.download_corpora
```

### 3. Lancer le Pipeline

Ouvrez 3 terminaux distincts et lancez les commandes dans cet ordre :

#### Terminal 1 : GÃ©nÃ©rateur de DonnÃ©es

```bash
python3 src/generator/post_generator_v2.py
```

Le script commencera Ã  envoyer des messages. Une crise alÃ©atoire sera simulÃ©e pÃ©riodiquement.

#### Terminal 2 : Moteur de Traitement (Spark)

```bash
python3 src/processor/spark_processor.py
```

Attendre l'initialisation de la JVM et le message "Streaming started".

#### Terminal 3 : Dashboard Web

```bash
streamlit run src/dashboard/web_dashboard.py
```

Le dashboard s'ouvrira automatiquement dans votre navigateur (http://localhost:8501).

---

## ğŸ“‚ Structure du Projet

```
sentiment-analysis/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ cassandra_schema.cql         # SchÃ©ma de la base de donnÃ©es
â”œâ”€â”€ docs/                            # Documentation et images
â”œâ”€â”€ ressources/                      # Screenshots et images du projet
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ generator/
â”‚   â”‚   â””â”€â”€ post_generator.py        # Simulateur de trafic (Normal + Crise)
â”‚   â”œâ”€â”€ processor/
â”‚   â”‚   â””â”€â”€ spark_processor.py       # Pipeline ETL Spark Streaming
â”‚   â””â”€â”€ dashboard/
â”‚       â””â”€â”€ web_dashboard.py         # Interface Web Streamlit
â”œâ”€â”€ requirements.txt                 # DÃ©pendances Python
â””â”€â”€ system_events.log                # Logs automatiques des crises dÃ©tectÃ©es
```

---

## ğŸ› ï¸ DifficultÃ©s RencontrÃ©es & Solutions

| ProblÃ¨me | Solution |
|----------|----------|
| **CompatibilitÃ© Spark/Java:** Spark 3.5 nÃ©cessitait Java 11 | Forcer `JAVA_HOME` vers OpenJDK 11 |
| **Driver Cassandra & Python 3.12:** Erreur de compilation des extensions C | Installation en mode "Pure Python" (`CASSANDRA_DRIVER_NO_EXTENSIONS=1`) |
| **Kafka Legacy:** La librairie `kafka-python` n'Ã©tait plus compatible | RemplacÃ©e par `kafka-python-ng` |
