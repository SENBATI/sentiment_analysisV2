üõ°Ô∏è Social Sentinel: Analyse de Sentiment en Temps R√©el
Module : Clusters Big Data & Syst√®mes Distribu√©s
Ann√©e : 2025/2026
Auteur : [Votre Nom]
üìñ Description du Projet
Ce projet impl√©mente une architecture Big Data compl√®te ("Kappa Architecture") pour surveiller la e-r√©putation des grandes entreprises marocaines (Maroc Telecom, Orange, RAM, etc.).
Le syst√®me ing√®re des flux de r√©seaux sociaux en temps r√©el, analyse le sentiment des messages (Positif/N√©gatif/Neutre) gr√¢ce au NLP, et d√©clenche des alertes imm√©diates en cas de crise (ex: chute brutale de satisfaction due √† une panne r√©seau).
Objectifs atteints :
Ingestion Haute Fr√©quence : Supporte des pics de charge (mode "Burst").
Faible Latence : D√©tection de crise en < 10 secondes.
Visualisation : Dashboard interactif Web (Streamlit).
Stockage : Historisation compl√®te et agr√©gations temporelles.
üèóÔ∏è Architecture Technique
Le pipeline de donn√©es suit le flux suivant :
G√©n√©rateur (Python) : Simule un flux de r√©seaux sociaux r√©aliste avec des sc√©narios de crise pond√©r√©s.
Ingestion (Apache Kafka) : Tamponne les messages dans le topic social_posts (3 partitions).
Traitement (Apache Spark Streaming) :
Consommation des micro-batchs.
Nettoyage et Analyse de Sentiment (TextBlob).
Agr√©gation par fen√™tres glissantes (Windowing 1 min).
Stockage (Apache Cassandra) : Sauvegarde des tweets bruts et des m√©triques agr√©g√©es.
Visualisation (Streamlit + Plotly) : Interface de monitoring temps r√©el avec syst√®me d'alerte.
üì∏ D√©monstration & Screenshots
1. Dashboard en mode "Surveillance Normale"
Cette vue montre le flux de donn√©es en temps r√©el. On observe les volumes de posts par marque et une courbe de sentiment stable.
(Ins√©rer ici le screenshot du dashboard avec les courbes bleues/vertes)
2. D√©tection de Crise (Simulation)
Lorsqu'une marque (ex: Maroc Telecom) subit une vague de commentaires n√©gatifs, le syst√®me d√©clenche une alerte visuelle rouge et notifie l'op√©rateur en moins de 5 secondes.
(Ins√©rer ici le screenshot avec la banni√®re ROUGE "CRITICAL ALERT" et le graphique en chute)
3. Preuve de Stockage (Cassandra)
Vue de la base de donn√©es montrant les tweets bruts et les scores de sentiment associ√©s, prouvant que le pipeline d'√©criture fonctionne.
(Ins√©rer ici le screenshot de votre terminal avec la commande SELECT * FROM posts LIMIT 10;)
üöÄ Installation et D√©marrage
Pr√©requis
Docker (pour Kafka et Cassandra)
Python 3.10+
Java 11 (Requis pour Spark)
1. D√©marrer l'Infrastructure
Assurez-vous que les conteneurs Docker tournent :
# D√©marrer Cassandra
docker run --name cassandra -p 9042:9042 -d cassandra:4.1

# V√©rifier Kafka (d√©j√† install√© sur votre machine/docker)
# Cr√©er le topic si n√©cessaire :
docker exec -it kafka kafka-topics --create --topic social_posts --partitions 3 --bootstrap-server localhost:9092


2. Installer les d√©pendances Python
pip install -r requirements.txt
python -m textblob.download_corpora


3. Lancer le Pipeline
Ouvrez 3 terminaux distincts et lancez les commandes dans cet ordre :
Terminal 1 : G√©n√©rateur de Donn√©es
python3 src/generator/post_generator_v2.py


Le script commencera √† envoyer des messages. Une crise al√©atoire sera simul√©e p√©riodiquement.
Terminal 2 : Moteur de Traitement (Spark)
python3 src/processor/spark_processor.py


Attendre l'initialisation de la JVM et le message "Streaming started".
Terminal 3 : Dashboard Web
streamlit run src/dashboard/web_dashboard.py


Le dashboard s'ouvrira automatiquement dans votre navigateur (http://localhost:8501).
üìÇ Structure du Projet
sentiment-analysis/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ cassandra_schema.cql    # Sch√©ma de la base de donn√©es
‚îú‚îÄ‚îÄ docs/                       # Documentation et images
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ generator/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ post_generator.py # Simulateur de trafic (Normal + Crise)
‚îÇ   ‚îú‚îÄ‚îÄ processor/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ spark_processor.py   # Pipeline ETL Spark Streaming
‚îÇ   ‚îî‚îÄ‚îÄ dashboard/
‚îÇ       ‚îî‚îÄ‚îÄ web_dashboard.py     # Interface Web Streamlit
‚îú‚îÄ‚îÄ requirements.txt            # D√©pendances Python
‚îî‚îÄ‚îÄ system_events.log           # Logs automatiques des crises d√©tect√©es


üõ†Ô∏è Difficult√©s Rencontr√©es & Solutions
Compatibilit√© Spark/Java : Spark 3.5 n√©cessitait Java 11. Solution : Forcer JAVA_HOME vers OpenJDK 11.
Driver Cassandra & Python 3.12 : Erreur de compilation des extensions C. Solution : Installation en mode "Pure Python" (CASSANDRA_DRIVER_NO_EXTENSIONS=1).
Kafka Legacy : La librairie kafka-python n'√©tait plus compatible. Remplac√©e par kafka-python-ng.
